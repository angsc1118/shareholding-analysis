# 2025-12-20 15:30:00: [Debug] é‚è¼¯å±¤ - å¼·åˆ¶é¡¯ç¤ºåŽŸå§‹æ•¸æ“šç‹€æ…‹ï¼Œè¨ºæ–·è³‡æ–™æ··é›œå•é¡Œ
import pandas as pd
import yfinance as yf
import streamlit as st
from src.database import get_market_snapshot, get_stock_raw_history

# --- å¸‚å ´é¢ (ä¿æŒä¸è®Š) ---
def calculate_top_growth(this_week_date: str, last_week_date: str, top_n=20) -> pd.DataFrame:
    df_this = get_market_snapshot(this_week_date, level=15)
    df_last = get_market_snapshot(last_week_date, level=15)
    
    if df_this.empty or df_last.empty:
        return pd.DataFrame()

    merged = pd.merge(
        df_this[['stock_id', 'percent', 'shares']], 
        df_last[['stock_id', 'percent']], 
        on='stock_id', 
        suffixes=('_this', '_last')
    )

    merged['change_pct'] = merged['percent_this'] - merged['percent_last']
    result = merged.sort_values('change_pct', ascending=False).head(top_n)
    
    final_df = result[['stock_id', 'percent_this', 'change_pct', 'shares']].copy()
    final_df.columns = ['è‚¡ç¥¨ä»£è™Ÿ', 'å¤§æˆ¶æŒè‚¡æ¯”%', 'é€±å¢žæ¸›%', 'æŒæœ‰è‚¡æ•¸']
    return final_df

# --- å€‹è‚¡é¢ ---
def fetch_stock_price(stock_id: str, start_date: str, end_date: str) -> dict:
    try:
        ticker = f"{stock_id}.TW"
        end_buffer = pd.to_datetime(end_date) + pd.Timedelta(days=5)
        data = yf.Ticker(ticker).history(start=start_date, end=end_buffer)
        
        if data.empty:
            ticker = f"{stock_id}.TWO"
            data = yf.Ticker(ticker).history(start=start_date, end=end_buffer)
        
        if data.empty:
            return {}

        data.index = data.index.strftime('%Y-%m-%d')
        return data['Close'].to_dict()
    except Exception as e:
        return {}

def get_stock_distribution_table(stock_id: str) -> pd.DataFrame:
    """ç”¢ç”Ÿè©³ç´°ç±Œç¢¼è¡¨ (Debug Mode)"""
    
    # 1. æ¸…æ´— Stock ID
    clean_stock_id = str(stock_id).strip()
    
    # 2. æ’ˆå–è³‡æ–™
    raw_df = get_stock_raw_history(clean_stock_id)
    
    # ================= [DEBUG START] =================
    # åœ¨ç¶²é ä¸Šç›´æŽ¥å°å‡ºé™¤éŒ¯è³‡è¨Š
    with st.expander("ðŸš¨ DATA DEBUGGER (è³‡æ–™è¨ºæ–·å®¤)", expanded=True):
        st.write(f"ðŸŽ¯ æŸ¥è©¢ç›®æ¨™ Stock ID: `{clean_stock_id}` (len={len(clean_stock_id)})")
        
        if raw_df.empty:
            st.error("âŒ get_stock_raw_history å›žå‚³ç‚ºç©ºï¼")
        else:
            # æª¢æŸ¥ 1: å›žå‚³è³‡æ–™ä¸­åŒ…å«å“ªäº›è‚¡ç¥¨ä»£è™Ÿï¼Ÿ
            unique_stocks = raw_df['stock_id'].unique()
            st.write(f"ðŸ“¦ è³‡æ–™åº«å›žå‚³äº†å“ªäº›è‚¡ç¥¨: {unique_stocks}")
            
            if len(unique_stocks) > 1:
                st.error(f"âš ï¸ åš´é‡è­¦å‘Šï¼šæ’ˆå›žäº†å¤šæ”¯è‚¡ç¥¨ï¼è«‹æª¢æŸ¥ database.py çš„éŽæ¿¾é‚è¼¯ã€‚")
            
            # æª¢æŸ¥ 2: éš¨æ©Ÿå–ä¸€å¤©çš„è³‡æ–™ä¾†æª¢æŸ¥ level æ˜¯å¦é‡è¤‡
            sample_date = raw_df['date'].iloc[0]
            st.write(f"ðŸ“… æŠ½æŸ¥æ—¥æœŸ: `{sample_date}`")
            
            # æ¨¡æ“¬è¨ˆç®—é‚è¼¯å‰çš„ç¯©é¸
            # æ³¨æ„ï¼šé€™è£¡åˆ»æ„ä¸åŠ  drop_duplicatesï¼Œçœ‹çœ‹åŽŸå§‹æ¨£è²Œ
            debug_day_data = raw_df[
                (raw_df['date'] == sample_date) & 
                (raw_df['stock_id'] == clean_stock_id)
            ]
            
            st.write("ðŸ“Š è©²æ—¥æœŸçš„åŽŸå§‹è³‡æ–™ (å‰ 20 ç­†):")
            st.dataframe(debug_day_data)
            
            # æª¢æŸ¥ 3: çµ±è¨ˆ Level é‡è¤‡ç‹€æ³
            level_counts = debug_day_data['level'].value_counts()
            if (level_counts > 1).any():
                st.error("âš ï¸ ç™¼ç¾ Level é‡è¤‡ï¼é€™ä»£è¡¨åŒä¸€å¤©ã€åŒä¸€æ”¯è‚¡ç¥¨ã€åŒä¸€å€‹ Level æœ‰å¤šç­†æ•¸æ“šã€‚")
                st.write(level_counts)
            else:
                st.success("âœ… è©²æ—¥æœŸçš„ Level æ²’æœ‰é‡è¤‡ï¼Œè³‡æ–™çµæ§‹æ­£å¸¸ã€‚")

            # æª¢æŸ¥ 4: è©¦ç®—ä¸€ä¸‹åŠ ç¸½
            total_sum = debug_day_data[debug_day_data['level'] >= 12]['persons'].sum()
            st.write(f"ðŸ§® æ¸¬è©¦åŠ ç¸½ (Level >= 12) äººæ•¸: {total_sum}")
    # ================= [DEBUG END] =================

    if raw_df.empty:
        return pd.DataFrame()

    # [Fix] è½‰åž‹
    cols_to_numeric = ['level', 'persons', 'shares', 'percent']
    for col in cols_to_numeric:
        if col in raw_df.columns:
            raw_df[col] = pd.to_numeric(raw_df[col], errors='coerce')

    dates = raw_df['date'].unique()
    rows = []

    for d in dates:
        d_str = str(d)
        
        # [Filter] åš´æ ¼ç¯©é¸
        day_data = raw_df[
            (raw_df['date'] == d) & 
            (raw_df['stock_id'] == clean_stock_id)
        ].copy()
        
        if day_data.empty:
            continue
        
        # [Fix] åŽ»é‡è¤‡ï¼šè‹¥ DB æœ‰é«’è³‡æ–™ï¼Œå¼·åˆ¶åªç•™ä¸€ç­†
        day_data = day_data.drop_duplicates(subset=['level'], keep='first')

        total_persons = day_data['persons'].sum()
        total_shares = day_data['shares'].sum()
        avg_shares = (total_shares / total_persons / 1000) if total_persons > 0 else 0
        
        def get_level_data(lvl):
            row = day_data[day_data['level'] == lvl]
            if not row.empty:
                return row.iloc[0]['persons'], row.iloc[0]['percent'], row.iloc[0]['shares']
            return 0, 0.0, 0

        p_1000, pct_1000, _ = get_level_data(15)
        
        big_holders_data = day_data[day_data['level'] >= 12]
        big_holders_pct = big_holders_data['percent'].sum()
        big_holders_persons = big_holders_data['persons'].sum()

        row = {
            'date': d_str,
            'ç¸½è‚¡æ±æ•¸': total_persons,
            'å¹³å‡å¼µæ•¸/äºº': avg_shares,
            '>400å¼µ_æ¯”ä¾‹': big_holders_pct,
            '>400å¼µ_äººæ•¸': big_holders_persons,
            '>1000å¼µ_æ¯”ä¾‹': pct_1000,
            '>1000å¼µ_äººæ•¸': p_1000
        }
        rows.append(row)
    
    df_pivot = pd.DataFrame(rows)
    
    if not df_pivot.empty:
        sorted_dates = df_pivot['date'].sort_values()
        start_date = sorted_dates.iloc[0]
        end_date = sorted_dates.iloc[-1]
        
        price_map = fetch_stock_price(clean_stock_id, start_date, end_date)
        df_pivot['æ”¶ç›¤åƒ¹'] = df_pivot['date'].map(price_map)

    df_pivot = df_pivot.sort_values('date', ascending=True)
    cols_to_diff = ['ç¸½è‚¡æ±æ•¸', 'å¹³å‡å¼µæ•¸/äºº', '>400å¼µ_æ¯”ä¾‹', '>400å¼µ_äººæ•¸', '>1000å¼µ_æ¯”ä¾‹', '>1000å¼µ_äººæ•¸', 'æ”¶ç›¤åƒ¹']
    
    for col in cols_to_diff:
        if col in df_pivot.columns:
            df_pivot[f'{col}_diff'] = df_pivot[col].diff()
    
    df_pivot = df_pivot.sort_values('date', ascending=False)
    
    return df_pivot
