# 2024-12-16 21:30:00: [Feat] æ–°å¢æ¸…æ´—è¦å‰‡: å»é™¤ç©ºç™½ã€åƒ…ä¿ç•™4ç¢¼å€‹è‚¡
import os
import sys
import requests
import pandas as pd
import io
import re  # æ–°å¢ regex æ¨¡çµ„
from datetime import datetime
from supabase import create_client, Client

# --- 1. è¨­å®šèˆ‡å¸¸æ•¸ ---
TDCC_URL = "https://smart.tdcc.com.tw/opendata/getOD.ashx?id=1-5"
SUPABASE_URL = (os.environ.get("SUPABASE_URL") or "").strip().rstrip("/")
SUPABASE_KEY = (os.environ.get("SUPABASE_SERVICE_KEY") or "").strip()
BUCKET_NAME = "tdcc_raw_files"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
}

if not SUPABASE_URL or not SUPABASE_KEY:
    print("âŒ éŒ¯èª¤: ç¼ºå°‘ç’°å¢ƒè®Šæ•¸ SUPABASE_URL æˆ– SUPABASE_SERVICE_KEY")
    sys.exit(1)

try:
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
except Exception as e:
    print(f"âŒ Supabase åˆå§‹åŒ–å¤±æ•—: {e}")
    sys.exit(1)

def run_etl():
    print(f"ğŸš€ é–‹å§‹åŸ·è¡Œ ETL ä»»å‹™: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # --- 2. ä¸‹è¼‰è³‡æ–™ (Extract) ---
    print("ğŸ“¥ æ­£åœ¨å¾é›†ä¿ä¸­å¿ƒä¸‹è¼‰ CSV...")
    try:
        response = requests.get(TDCC_URL, headers=HEADERS, timeout=60)
        response.raise_for_status()
        raw_content = response.content
        print(f"   ä¸‹è¼‰æˆåŠŸï¼æª”æ¡ˆå¤§å°: {len(raw_content) / 1024:.2f} KB")
    except Exception as e:
        print(f"âŒ ä¸‹è¼‰å¤±æ•—: {e}")
        sys.exit(1)

    # --- 3. å‚™ä»½åŸå§‹æª” (Backup) ---
    today_str = datetime.now().strftime("%Y%m%d")
    backup_filename = f"TDCC_{today_str}.csv"
    
    print(f"ğŸ’¾ æ­£åœ¨å‚™ä»½è‡³ Storage: {backup_filename}...")
    try:
        supabase.storage.from_(BUCKET_NAME).upload(
            path=backup_filename,
            file=raw_content,
            file_options={"content-type": "text/csv", "upsert": "true"}
        )
        print("   âœ… å‚™ä»½æˆåŠŸï¼")
    except Exception as e:
        print(f"âš ï¸ å‚™ä»½è­¦ç¤º: {e}")

    # --- 4. è³‡æ–™æ¸…æ´— (Transform) ---
    print("ğŸ§¹ æ­£åœ¨æ¸…æ´—è³‡æ–™...")
    df = None
    
    # å˜—è©¦è§£ç¢¼
    try:
        df = pd.read_csv(io.BytesIO(raw_content), encoding="utf-8", dtype=str)
    except UnicodeDecodeError:
        try:
            df = pd.read_csv(io.BytesIO(raw_content), encoding="big5", dtype=str)
        except Exception as e:
            print(f"âŒ è§£ç¢¼å¤±æ•—: {e}")
            sys.exit(1)

    try:
        if len(df.columns) >= 6:
            df.columns = ["date", "stock_id", "level", "persons", "shares", "percent"]
        else:
            raise ValueError(f"CSV æ¬„ä½ä¸è¶³: {len(df.columns)}")

        # [æ–°å¢è¦å‰‡] è™•ç† stock_id: å»ç©ºç™½ + ç¯©é¸4ç¢¼æ•¸å­—
        original_count = len(df)
        df['stock_id'] = df['stock_id'].astype(str).str.strip() # å»é™¤å‰å¾Œç©ºç™½
        
        # ä½¿ç”¨ Regex ç¯©é¸: ^\d{4}$ ä»£è¡¨å¾é ­åˆ°å°¾åªæœ‰4å€‹æ•¸å­—
        # æ’é™¤ 0050(ETF), 2330(å€‹è‚¡) -> ä¿ç•™
        # æ’é™¤ 23301(æœŸè²¨?), 99999(åˆè¨ˆ), 00632R(ETF) -> å‰”é™¤
        df = df[df['stock_id'].str.match(r'^\d{4}$')]
        
        filtered_count = len(df)
        print(f"   [ç¯©é¸] åƒ…ä¿ç•™ 4 ç¢¼å€‹è‚¡: {original_count} -> {filtered_count} (å‰”é™¤ {original_count - filtered_count} ç­†)")

        # æ—¥æœŸè™•ç†
        def convert_date(date_str):
            if pd.isna(date_str): return None
            s = str(date_str).strip()
            try:
                if len(s) == 8: return f"{s[:4]}-{s[4:6]}-{s[6:]}"
                elif len(s) == 7:
                    return f"{int(s[:-4]) + 1911}-{s[-4:-2]}-{s[-2:]}"
                elif '/' in s or '-' in s:
                    return pd.to_datetime(s).strftime('%Y-%m-%d')
                return None
            except: return None

        df['date'] = df['date'].apply(convert_date)

        # æ•¸å€¼è™•ç†
        for col in ['persons', 'shares', 'percent']:
            df[col] = df[col].str.replace(',', '', regex=False)
            df[col] = pd.to_numeric(df[col], errors='coerce')
        
        df['level'] = pd.to_numeric(df['level'], errors='coerce')

        # ç§»é™¤ç„¡æ•ˆè³‡æ–™
        df.dropna(subset=['date', 'stock_id', 'level'], inplace=True)
        
        print(f"   æ¸…æ´—å®Œæˆï¼æº–å‚™å¯«å…¥ {len(df)} ç­†è³‡æ–™...")

    except Exception as e:
        print(f"âŒ æ¸…æ´—å¤±æ•—: {e}")
        sys.exit(1)

    # --- 5. å¯«å…¥è³‡æ–™åº« (Load) ---
    print("ğŸ“¤ æ­£åœ¨å¯«å…¥è³‡æ–™åº«...")
    records = df.to_dict(orient='records')
    BATCH_SIZE = 1000
    total_inserted = 0
    
    try:
        for i in range(0, len(records), BATCH_SIZE):
            batch = records[i : i + BATCH_SIZE]
            supabase.table("equity_distribution").upsert(batch).execute()
            total_inserted += len(batch)
            if (i // BATCH_SIZE) % 10 == 0:
                 print(f"   å·²å¯«å…¥: {total_inserted} / {len(records)}")
            
        print(f"âœ… ETL å®Œæˆï¼å…±å¯«å…¥ {total_inserted} ç­†ã€‚")

    except Exception as e:
        print(f"âŒ å¯«å…¥å¤±æ•—: {e}")
        sys.exit(1)

if __name__ == "__main__":
    run_etl()
