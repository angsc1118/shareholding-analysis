# 2024-12-16 20:00:00: [Fix] ä¿®æ­£ç·¨ç¢¼ç‚º UTF-8ã€æ”¯æ´è¥¿å…ƒå¹´æ ¼å¼ã€æ¸…æ´— URL
import os
import sys
import requests
import pandas as pd
import io
from datetime import datetime
from supabase import create_client, Client

# --- 1. è¨­å®šèˆ‡å¸¸æ•¸ ---
TDCC_URL = "https://smart.tdcc.com.tw/opendata/getOD.ashx?id=1-5"
# æ¸…æ´—ç’°å¢ƒè®Šæ•¸ï¼Œç§»é™¤å¯èƒ½å­˜åœ¨çš„ç©ºç™½æˆ–çµå°¾æ–œç·š
SUPABASE_URL = (os.environ.get("SUPABASE_URL") or "").strip().rstrip("/")
SUPABASE_KEY = (os.environ.get("SUPABASE_SERVICE_KEY") or "").strip()
BUCKET_NAME = "tdcc_raw_files"

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
}

# æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
if not SUPABASE_URL or not SUPABASE_KEY:
    print("âŒ éŒ¯èª¤: ç¼ºå°‘ç’°å¢ƒè®Šæ•¸ SUPABASE_URL æˆ– SUPABASE_SERVICE_KEY")
    sys.exit(1)

# åˆå§‹åŒ– Supabase
try:
    supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)
except Exception as e:
    print(f"âŒ Supabase åˆå§‹åŒ–å¤±æ•—: {e}")
    sys.exit(1)

def run_etl():
    print(f"ğŸš€ é–‹å§‹åŸ·è¡Œ ETL ä»»å‹™: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # --- 2. ä¸‹è¼‰è³‡æ–™ (Extract) ---
    print("ğŸ“¥ æ­£åœ¨å¾é›†ä¿ä¸­å¿ƒä¸‹è¼‰ CSV (å·²å½è£ Header)...")
    try:
        response = requests.get(TDCC_URL, headers=HEADERS, timeout=60)
        response.raise_for_status()
        raw_content = response.content
        print(f"   ä¸‹è¼‰æˆåŠŸï¼æª”æ¡ˆå¤§å°: {len(raw_content) / 1024:.2f} KB")
    except Exception as e:
        print(f"âŒ ä¸‹è¼‰å¤±æ•—: {e}")
        sys.exit(1)

    # --- 3. å‚™ä»½åŸå§‹æª” (Backup to Storage) ---
    today_str = datetime.now().strftime("%Y%m%d")
    backup_filename = f"TDCC_{today_str}.csv"
    
    print(f"ğŸ’¾ æ­£åœ¨å‚™ä»½åŸå§‹æª”è‡³ Storage: {backup_filename}...")
    try:
        # ä¿®æ­£: ç¢ºä¿ file_options æ­£ç¢º
        supabase.storage.from_(BUCKET_NAME).upload(
            path=backup_filename,
            file=raw_content,
            file_options={"content-type": "text/csv", "upsert": "true"}
        )
        print("   âœ… å‚™ä»½æˆåŠŸï¼")
    except Exception as e:
        # å‚™ä»½å¤±æ•—é€šå¸¸ä¸å½±éŸ¿å¾ŒçºŒæµç¨‹ï¼Œå°å‡ºè­¦å‘Šå³å¯
        print(f"âš ï¸ å‚™ä»½è­¦ç¤º (éè‡´å‘½): {e}")

    # --- 4. è³‡æ–™æ¸…æ´— (Transform) ---
    print("ğŸ§¹ æ­£åœ¨æ¸…æ´—è³‡æ–™...")
    df = None
    
    # å˜—è©¦å¤šç¨®ç·¨ç¢¼è®€å–
    try:
        # å„ªå…ˆå˜—è©¦ UTF-8 (è¿‘æœŸ TDCC æ ¼å¼)
        print("   å˜—è©¦ä½¿ç”¨ utf-8 è§£ç¢¼...")
        df = pd.read_csv(io.BytesIO(raw_content), encoding="utf-8", dtype=str)
    except UnicodeDecodeError:
        try:
            # å¤±æ•—å‰‡å˜—è©¦ Big5 (èˆŠæ ¼å¼)
            print("   utf-8 å¤±æ•—ï¼Œæ”¹ç”¨ big5 è§£ç¢¼...")
            df = pd.read_csv(io.BytesIO(raw_content), encoding="big5", dtype=str)
        except Exception as e:
            print(f"âŒ è³‡æ–™è§£ç¢¼å®Œå…¨å¤±æ•—: {e}")
            sys.exit(1)

    try:
        # é‡æ–°å‘½åæ¬„ä½ (ç¢ºä¿å°æ‡‰è³‡æ–™åº«)
        # é æœŸæ¬„ä½: è³‡æ–™æ—¥æœŸ,è­‰åˆ¸ä»£è™Ÿ,æŒè‚¡åˆ†ç´š,äººæ•¸,è‚¡æ•¸,å é›†ä¿åº«å­˜æ•¸æ¯”ä¾‹%
        if len(df.columns) >= 6:
            df.columns = ["date", "stock_id", "level", "persons", "shares", "percent"]
        else:
            raise ValueError(f"CSV æ¬„ä½æ•¸é‡ä¸è¶³ ({len(df.columns)})ï¼Œé æœŸè‡³å°‘ 6 æ¬„")

        # --- æ—¥æœŸè½‰æ›é‚è¼¯ (æ”¯æ´ è¥¿å…ƒå¹´ èˆ‡ æ°‘åœ‹å¹´) ---
        def convert_date(date_str):
            if pd.isna(date_str): return None
            s = str(date_str).strip()
            
            try:
                # Case 1: 8ä½æ•¸è¥¿å…ƒå¹´ (ä¾‹å¦‚ 20251212)
                if len(s) == 8:
                    return f"{s[:4]}-{s[4:6]}-{s[6:]}"
                
                # Case 2: 7ä½æ•¸æ°‘åœ‹å¹´ (ä¾‹å¦‚ 1141212)
                elif len(s) == 7:
                    year = int(s[:-4]) + 1911
                    month = s[-4:-2]
                    day = s[-2:]
                    return f"{year}-{month}-{day}"
                
                # Case 3: å·²ç¶“æ˜¯æ ¼å¼åŒ–çš„æ—¥æœŸ (ä¾‹å¦‚ 2025/12/12)
                elif '/' in s or '-' in s:
                    return pd.to_datetime(s).strftime('%Y-%m-%d')
                
                else:
                    return None
            except:
                return None

        df['date'] = df['date'].apply(convert_date)

        # æ•¸å€¼æ¸…æ´—
        cols_to_clean = ['persons', 'shares', 'percent']
        for col in cols_to_clean:
            df[col] = df[col].str.replace(',', '', regex=False)
            df[col] = pd.to_numeric(df[col], errors='coerce')

        df['level'] = pd.to_numeric(df['level'], errors='coerce')

        # ç§»é™¤ç©ºå€¼åˆ—
        df.dropna(subset=['date', 'stock_id', 'level'], inplace=True)
        
        print(f"   æ¸…æ´—å®Œæˆï¼æº–å‚™å¯«å…¥ {len(df)} ç­†è³‡æ–™...")
        # é¡¯ç¤ºå‰ä¸€ç­†è³‡æ–™ä¾›ç¢ºèª
        print(f"   [Preview] ç¬¬ä¸€ç­†è³‡æ–™: {df.iloc[0].to_dict()}")

    except Exception as e:
        print(f"âŒ è³‡æ–™æ¸…æ´—é‚è¼¯å¤±æ•—: {e}")
        sys.exit(1)

    # --- 5. å¯«å…¥è³‡æ–™åº« (Load / Upsert) ---
    print("ğŸ“¤ æ­£åœ¨å¯«å…¥ Supabase è³‡æ–™åº« (åˆ†æ‰¹å¯«å…¥)...")
    
    records = df.to_dict(orient='records')
    BATCH_SIZE = 1000
    total_inserted = 0
    
    try:
        for i in range(0, len(records), BATCH_SIZE):
            batch = records[i : i + BATCH_SIZE]
            supabase.table("equity_distribution").upsert(batch).execute()
            total_inserted += len(batch)
            
            if (i // BATCH_SIZE) % 10 == 0:
                 print(f"   å·²å¯«å…¥: {total_inserted} / {len(records)}")
            
        print(f"âœ… ETL ä»»å‹™å…¨éƒ¨å®Œæˆï¼ç¸½å…±å¯«å…¥ {total_inserted} ç­†è³‡æ–™ã€‚")

    except Exception as e:
        print(f"âŒ è³‡æ–™åº«å¯«å…¥å¤±æ•—: {e}")
        sys.exit(1)

if __name__ == "__main__":
    run_etl()
