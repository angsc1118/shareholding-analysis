# 2025-12-16 19:10:00: [Fix] åŠ å…¥ User-Agent Header è§£æ±º TDCC é‡æ–°å°å‘(Redirect Loop)å•é¡Œ
import os
import sys
import requests
import pandas as pd
import io
from datetime import datetime
from supabase import create_client, Client

# --- 1. è¨­å®šèˆ‡å¸¸æ•¸ ---
TDCC_URL = "https://smart.tdcc.com.tw/opendata/getOD.ashx?id=1-5"
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_SERVICE_KEY")
BUCKET_NAME = "tdcc_raw_files"

# [æ–°å¢] å½è£æˆç€è¦½å™¨çš„ Header
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
    "Accept-Language": "zh-TW,zh;q=0.9,en-US;q=0.8,en;q=0.7"
}

# æª¢æŸ¥ç’°å¢ƒè®Šæ•¸
if not SUPABASE_URL or not SUPABASE_KEY:
    print("âŒ éŒ¯èª¤: ç¼ºå°‘ç’°å¢ƒè®Šæ•¸ SUPABASE_URL æˆ– SUPABASE_SERVICE_KEY")
    sys.exit(1)

# åˆå§‹åŒ– Supabase
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

def run_etl():
    print(f"ğŸš€ é–‹å§‹åŸ·è¡Œ ETL ä»»å‹™: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # --- 2. ä¸‹è¼‰è³‡æ–™ (Extract) ---
    print("ğŸ“¥ æ­£åœ¨å¾é›†ä¿ä¸­å¿ƒä¸‹è¼‰ CSV (å·²å½è£ Header)...")
    try:
        # [ä¿®æ”¹] åŠ å…¥ headers åƒæ•¸
        response = requests.get(TDCC_URL, headers=HEADERS, timeout=60)
        
        # æª¢æŸ¥æ˜¯å¦è¢«è½‰å€åˆ°å¥‡æ€ªçš„åœ°æ–¹ (Optional debug)
        if response.history:
            print(f"   (Info) ç¶“éè½‰å€: {[r.url for r in response.history]}")
            
        response.raise_for_status()
        raw_content = response.content
        print(f"   ä¸‹è¼‰æˆåŠŸï¼æª”æ¡ˆå¤§å°: {len(raw_content) / 1024:.2f} KB")
        
        # ç°¡å–®æª¢æŸ¥å…§å®¹æ˜¯å¦ç‚º HTML (æœ‰æ™‚å€™ä¸‹è¼‰æˆåŠŸä½†å…§å®¹æ˜¯éŒ¯èª¤ç¶²é )
        if raw_content[:15].decode('utf-8', errors='ignore').strip().lower().startswith('<!doctype html'):
             raise ValueError("ä¸‹è¼‰åˆ°çš„å…§å®¹ä¼¼ä¹æ˜¯ HTML ç¶²é è€Œé CSVï¼Œå¯èƒ½ä»è¢«é˜»æ“‹ã€‚")

    except Exception as e:
        print(f"âŒ ä¸‹è¼‰å¤±æ•—: {e}")
        sys.exit(1)

    # --- 3. å‚™ä»½åŸå§‹æª” (Backup to Storage) ---
    today_str = datetime.now().strftime("%Y%m%d")
    backup_filename = f"TDCC_{today_str}.csv"
    
    print(f"ğŸ’¾ æ­£åœ¨å‚™ä»½åŸå§‹æª”è‡³ Storage: {backup_filename}...")
    try:
        supabase.storage.from_(BUCKET_NAME).upload(
            path=backup_filename,
            file=raw_content,
            file_options={"content-type": "text/csv", "upsert": "true"}
        )
        print("   âœ… å‚™ä»½æˆåŠŸï¼")
    except Exception as e:
        print(f"âš ï¸ å‚™ä»½å¤±æ•— (å¯èƒ½æ˜¯æª”æ¡ˆå·²å­˜åœ¨): {e}")
    
    # --- 4. è³‡æ–™æ¸…æ´— (Transform) ---
    print("ğŸ§¹ æ­£åœ¨æ¸…æ´—è³‡æ–™...")
    try:
        # ä½¿ç”¨ Big5 è§£ç¢¼è®€å– CSV
        df = pd.read_csv(io.BytesIO(raw_content), encoding="big5", dtype=str)
        
        # é‡æ–°å‘½åæ¬„ä½
        df.columns = ["date", "stock_id", "level", "persons", "shares", "percent"]

        # è³‡æ–™è½‰æ›é‚è¼¯
        def convert_date(roc_date):
            if pd.isna(roc_date): return None
            roc_date = str(roc_date).strip()
            if len(roc_date) < 6: return None # ç•°å¸¸é•·åº¦
            
            try:
                year = int(roc_date[:-4]) + 1911
                month = roc_date[-4:-2]
                day = roc_date[-2:]
                return f"{year}-{month}-{day}"
            except:
                return None

        df['date'] = df['date'].apply(convert_date)

        cols_to_clean = ['persons', 'shares', 'percent']
        for col in cols_to_clean:
            df[col] = df[col].str.replace(',', '', regex=False)
            df[col] = pd.to_numeric(df[col], errors='coerce')

        df['level'] = pd.to_numeric(df['level'], errors='coerce')

        # ç§»é™¤ç©ºå€¼åˆ—
        df.dropna(subset=['date', 'stock_id', 'level'], inplace=True)
        
        print(f"   æ¸…æ´—å®Œæˆï¼æº–å‚™å¯«å…¥ {len(df)} ç­†è³‡æ–™...")

    except Exception as e:
        print(f"âŒ è³‡æ–™æ¸…æ´—å¤±æ•—: {e}")
        print("CSV Content Head (å‰ 500 bytes):")
        print(raw_content[:500].decode('big5', errors='ignore'))
        sys.exit(1)

    # --- 5. å¯«å…¥è³‡æ–™åº« (Load / Upsert) ---
    print("ğŸ“¤ æ­£åœ¨å¯«å…¥ Supabase è³‡æ–™åº« (åˆ†æ‰¹å¯«å…¥)...")
    
    records = df.to_dict(orient='records')
    BATCH_SIZE = 1000
    total_inserted = 0
    
    try:
        for i in range(0, len(records), BATCH_SIZE):
            batch = records[i : i + BATCH_SIZE]
            supabase.table("equity_distribution").upsert(batch).execute()
            total_inserted += len(batch)
            if (i // BATCH_SIZE) % 5 == 0: # æ¯ 5 æ‰¹å°ä¸€æ¬¡ Logï¼Œæ¸›å°‘é›œè¨Š
                 print(f"   å·²å¯«å…¥: {total_inserted} / {len(records)}")
            
        print("âœ… ETL ä»»å‹™å…¨éƒ¨å®Œæˆï¼")

    except Exception as e:
        print(f"âŒ è³‡æ–™åº«å¯«å…¥å¤±æ•—: {e}")
        sys.exit(1)

if __name__ == "__main__":
    run_etl()
